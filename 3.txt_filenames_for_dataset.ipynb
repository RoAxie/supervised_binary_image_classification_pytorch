{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb57279-6d08-471b-88e8-390a7d2ba450",
   "metadata": {},
   "source": [
    "# Creating two txt files, one for the training - validation dataset and one for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09fe51c-ed56-48eb-99f5-16d4a2251af9",
   "metadata": {},
   "source": [
    "The final outputs are two txt files: **'train_files.txt'** and **'test_files.txt'**. In each file, each line corresponds to an event: plane 0, plane 1, plane 2, label (0 or 1). Plane 0, 1, and 2 are the npz filenames needed to create the images. The elements are separated by ', '.  \n",
    "The structure is as follow: filename_plane0.extracted.npz, filename_plane1.extracted.npz, filename_plane2.extracted.npz, class\n",
    "\n",
    "This notebook works with npz files organized by plane and then by class, e.g., path_to_npz/0/ATMO.\n",
    "\n",
    "The 2 inputs required from the user are: the main directory where these files are located and the value needed to split the filenames into two subsets (test and train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64bed5-215a-4463-9cdb-973c685660c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bd191-9cbe-4a09-9d46-c8c3f0204741",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_dir = input(\"Please, write the path to npz files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cf7ad-236a-4b34-a13f-c6e7be54c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = input(\"Please, specify the size of the training set. Eg. if answer is 0.7 => 70% of the files will go into the training set and 30% of the files will go into the testing set\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4241f7-d921-4b90-9617-970c26adf838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating lists of filenames and labels from the directories')\n",
    "\n",
    "files = []\n",
    "labels = []\n",
    "\n",
    "# Directories for AtmoNu e PDK for 3 planes\n",
    "class_0_dirs = [f\"{npz_dir}/{plane}/ATMO\" for plane in range(3)]\n",
    "class_1_dirs = [f\"{npz_dir}/{plane}/PDK\" for plane in range(3)]\n",
    "\n",
    "# Function to collect event tuples and their labels from multiple directories\n",
    "def event_in_tuple(directories, label):\n",
    "    for f1, f2, f3 in zip(\n",
    "            sorted(os.listdir(directories[0])),  # Plane 0\n",
    "            sorted(os.listdir(directories[1])),  # Plane 1\n",
    "            sorted(os.listdir(directories[2]))): # Plane 2\n",
    "        # Files is a list of tuples. One tuple - one event. Each tuple has three elements beacuse each event has three planes.\n",
    "        files.append((f1, f2, f3))\n",
    "        labels.append(label)\n",
    "    return files, labels\n",
    "\n",
    "# Get files and labels for AtmoNu (0) and PDK (1)\n",
    "files0, labels0 = event_in_tuple(class_0_dirs, 0)\n",
    "files1, labels1 = event_in_tuple(class_1_dirs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def0a90-ee2c-450f-96aa-beb28199e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Splitting and shuffling the files')\n",
    "\n",
    "# Convert train_set_size input answer to a float to calculate the training set size\n",
    "train_size = float(train_set_size)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "# random.seed(667)\n",
    "\n",
    "# Create a list of ATMO (class 0) and PDK (class 1) file tuples with corresponding labels\n",
    "atmo_files = [(files0[i], labels0[i]) for i in range(len(files0)) if labels0[i] == 0]\n",
    "pdk_files = [(files1[i], labels1[i]) for i in range(len(files1)) if labels1[i] == 1]\n",
    "\n",
    "# Shuffle the file lists to randomize the order\n",
    "random.shuffle(atmo_files)\n",
    "random.shuffle(pdk_files)\n",
    "\n",
    "# Calculate the number of ATMO and PDK files to include in the training set\n",
    "train_atmo = int(len(atmo_files) * train_size)\n",
    "train_pdk = int(len(pdk_files) * train_size)\n",
    "\n",
    "# Split the files into training and testing sets\n",
    "all_train_files = atmo_files[:train_atmo] + pdk_files[:train_pdk]\n",
    "all_test_files = atmo_files[train_atmo:] + pdk_files[train_pdk:]\n",
    "\n",
    "# Shuffle the final training and testing sets\n",
    "random.shuffle(all_train_files)   # With both AtmoNu and PDK\n",
    "random.shuffle(all_test_files)    # With both AtmoNu and PDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d986338-51d9-42e0-a666-488f499ab93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating the txt files')\n",
    "\n",
    "# Function to save the list of files and labels to a text file\n",
    "def save_file_list(files, txt_filename):\n",
    "    with open(txt_filename, 'w') as f:\n",
    "        for event_tuple, label in files:\n",
    "            # Convert the tuple to a comma-separated string: removes usless () and ''\n",
    "            file_names = [file for file in event_tuple]\n",
    "            f.write(f\"{', '.join(file_names)}, {label}\\n\")\n",
    "\n",
    "# Save the training and testing file lists to text files\n",
    "save_file_list(all_train_files, 'train_files.txt')\n",
    "save_file_list(all_test_files, 'test_files.txt')\n",
    "\n",
    "print('Files saved')\n",
    "print('Execution completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
