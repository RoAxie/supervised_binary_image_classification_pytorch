{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db20a92-fd0e-474b-9d89-ba778f95dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import alexnet, vgg11, vgg19\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ea302d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM DATASET\n",
    "\n",
    "def create_image(img_path):\n",
    "    image = load_npz(img_path)\n",
    "    image = image.toarray()\n",
    "    image = np.resize(image, (1, 225, 225))\n",
    "\n",
    "    return image\n",
    "\n",
    "class PhysicsImageDataset(Dataset):\n",
    "    def __init__(self, file_dir='path/to/npz', subset='train', approach=None, transform=None, target_transform=None):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.approach = approach\n",
    "\n",
    "        txt_dir = 'path/to/txt'\n",
    "        txt_file = f\"{txt_dir}/{subset}_files.txt\"\n",
    "\n",
    "        with open(txt_file, 'r') as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(', ')\n",
    "                filenames = fields[:3]\n",
    "                label = int(fields[-1])\n",
    "                file_paths = (\n",
    "                    os.path.join(file_dir, \"0\", \"ATMO\" if label == 0 else \"PDK\", filenames[0]),\n",
    "                    os.path.join(file_dir, \"1\", \"ATMO\" if label == 0 else \"PDK\", filenames[1]),\n",
    "                    os.path.join(file_dir, \"2\", \"ATMO\" if label == 0 else \"PDK\", filenames[2])\n",
    "                )\n",
    "                self.files.append(file_paths)\n",
    "                self.labels.append(label)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_paths = self.files[idx]\n",
    "        images = []\n",
    "        for img_path in img_paths:\n",
    "            image = create_image(img_path)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.approach == 'EF': # Early Fusion\n",
    "                images.append(image.squeeze(0))\n",
    "            else:\n",
    "                images.append(image)\n",
    "\n",
    "        if self.approach == 'EF':\n",
    "            images = np.stack(images, axis = 0)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return images, label, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825a60b5-5514-440b-aa32-6fc76c91f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(model_path, plane = None):\n",
    "    if NETWORK == \"alexnet\":\n",
    "        net = alexnet(weights=None)\n",
    "    elif NETWORK == \"vgg11\":\n",
    "        net = vgg11(weights=None)\n",
    "    elif NETWORK == \"vgg19\":\n",
    "        net = vgg19(weights=None)\n",
    "    if plane != None:    \n",
    "        if plane == 0:\n",
    "            net = torch.load(model_path[NETWORK][0])\n",
    "        elif plane == 1:\n",
    "            net = torch.load(model_path[NETWORK][1])\n",
    "        else:\n",
    "            net = torch.load(model_path[NETWORK][2])\n",
    "    else:\n",
    "        net = torch.load(model_path[NETWORK])\n",
    "            \n",
    "    return net # Return the model with loaded weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890732d4-354d-462d-aa9b-180fbb268d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misclassified_paths_df(misclassified_paths, NETWORK):\n",
    "    data = []\n",
    "    for file_path in misclassified_paths:\n",
    "        _, filename = os.path.split(file_path)\n",
    "        base = filename.replace('.extracted.npz', '')\n",
    "        base = base.split('_')\n",
    "\n",
    "#       ['files', 'PDK', '2', 'larcv', 'plane0', '185']\n",
    "        atmonu_pdk = base[1]\n",
    "        mc_sim = int(base[2])\n",
    "        plane = int(base[-2][-1])\n",
    "        event = int(base[-1])\n",
    "        \n",
    "        # Append the extracted information as a dictionary to the data list\n",
    "        data.append({\n",
    "            'filename': filename,\n",
    "            'network' : NETWORK,\n",
    "            'atmonu_pdk': atmonu_pdk,\n",
    "            'mc_sim': mc_sim,\n",
    "            'plane': plane,\n",
    "            'event': event\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data) # The resulting DataFrame contains information on misclassified paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9042c93c-b523-4b97-aa7f-22adebadcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a38bb-bb5e-4f5d-b4b4-b27819da151f",
   "metadata": {},
   "source": [
    "# Late Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "919a9e5b-ba8f-41a6-96fc-50974a9ce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_outputs(list_of_outputs, METHOD = \"mean_probability\", threshold = 0.5):\n",
    "\n",
    "     #for output in list_of_outputs:\n",
    "         #print(output.shape)\n",
    "\n",
    "     outputs = torch.stack(list_of_outputs)\n",
    "     #print(outputs.shape)\n",
    "\n",
    "\n",
    "     if METHOD == \"voting\":\n",
    "        # Perform voting by taking the maximum value across classes\n",
    "         _, predicted = torch.max(outputs, 2)\n",
    "         # Average the predicted classes across all outputs and apply the threshold to determine the final prediction\n",
    "         predictions = (predicted.mean(dim=0, dtype=float)>= threshold)\n",
    "         return predictions\n",
    "\n",
    "     elif METHOD == \"mean_probability\":\n",
    "        # Apply the softmax function to each output to get probabilities (over the classes)\n",
    "         probabilities = torch.nn.functional.softmax(outputs, dim=2)\n",
    "         final_probs = probabilities.mean(dim=0)\n",
    "         # Check if the probability for class 1 is greater than or equal to the threshold\n",
    "         predictions = (final_probs[:, 1] >= threshold)\n",
    "         return predictions, final_probs[:, 1] # Return both the predictions and the final average probability for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44570b0e-1a49-4079-a817-a0d87418051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_latef(nets, testloader, pred_threshold):\n",
    "    \n",
    "    correct = 0\n",
    "    misclassified_test_paths = []\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs_lists, true_labels, img_paths in tqdm.tqdm(testloader, desc=f'Testing {NETWORK} - Late Fusion'):\n",
    "            imgs0, imgs1, imgs2 = imgs_lists\n",
    "            imgs0, imgs1, imgs2, true_labels = imgs0.cuda().float(), imgs1.cuda().float(), imgs2.cuda().float(), true_labels.cuda()\n",
    "            \n",
    "            outputs = [] \n",
    "            for imgs, net in zip([imgs0, imgs1, imgs2], nets):\n",
    "                outputs.append(net(imgs)) # Store the output of each network\n",
    "            \n",
    "            method = 'mean_probability' # or 'voting'\n",
    "            aggregated_predictions, aggregated_probabilities = aggregate_outputs(outputs, method, pred_threshold)\n",
    "            predictions.extend(aggregated_predictions.cpu().numpy())\n",
    "            labels.extend(true_labels.cpu().numpy())\n",
    "            probs.extend(aggregated_probabilities.cpu().numpy())\n",
    "            \n",
    "            indices_wrong = torch.nonzero(aggregated_predictions != true_labels).squeeze().tolist()\n",
    "            if type(indices_wrong) is int:\n",
    "                indices_wrong = [indices_wrong]\n",
    "            for idx in indices_wrong:\n",
    "                for img_path in img_paths:\n",
    "                    misclassified_test_paths.append(img_path[idx])\n",
    "    \n",
    "            correct += (true_labels == aggregated_predictions).sum()\n",
    "\n",
    "    # Calculate the false positive rate (fpr) and true positive rate (tpr) for ROC curve\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    # Calculate the area under the ROC curve (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Calculate accuracy as the percentage of correct predictions\n",
    "    accuracy = 100*correct/len(labels)      \n",
    "    print(f\"{NETWORK.capitalize()} - Late Fusion - Test accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    # Return all relevant metrics and the misclassified test paths\n",
    "    return predictions, labels, probs, fpr, tpr, roc_auc, misclassified_test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffb3427d-2182-413e-96fe-93962b0b34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for the saved models\n",
    "paths_lf = {\n",
    "    'alexnet' : [\"alexnet_net0_epoch.pth\", \"alexnet_net1_epoch.pth\", \"alexnet_net2_epoch.pth\"],\n",
    "    'vgg11' : [\"vgg11_net0_epoch.pth\", \"vgg11_net1_epoch.pth\", \"vgg11_net2_epoch.pth\"],\n",
    "    'vgg19' : [\"vgg19_net0_epoch.pth\", \"vgg19_net1_epoch.pth\", \"vgg19_net2_epoch.pth\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8cf83-3e6d-426b-a437-d04ba46c6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PhysicsImageDataset(subset='test')\n",
    "print(\"Test dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45dae7e0-75c1-4629-9f4a-f6ad949b6386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset.files[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd5de4c-c7a5-4b9e-bc7f-e6f172f2f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test dataset\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1546260-6af4-4f26-9ef0-7686351d1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Counting test labels')\n",
    "#class0 = 0\n",
    "#class1 = 0\n",
    "#for imgs, labels, img_paths in tqdm.tqdm(testloader):\n",
    "#    class0 += (labels == 0).sum().item()\n",
    "#    class1 += (labels == 1).sum().item()\n",
    "#tot = class0 + class1\n",
    "#print(f'Testloader: AtmoNu: {class0} {100*class0/tot:.2f}%, PDK: {class1} {100*class1/tot:.2f}%')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "197d9279-3861-433a-aec5-b367870cda0f",
   "metadata": {},
   "source": [
    "Test labels:\n",
    "Class 0: 25136 48.84%\n",
    "Class 1: 26335 51.16%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a58fa-dd5d-4195-9961-e297c81a279d",
   "metadata": {},
   "source": [
    "## alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8d296e-23f0-4da2-8e06-7dd6e005f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = 'alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d99598-f784-4f43-83dd-35ab0b4cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net0 = create_network(paths_lf, 0)\n",
    "net1 = create_network(paths_lf, 1)\n",
    "net2 = create_network(paths_lf, 2)\n",
    "for net in [net0, net1, net2]:\n",
    "    net = net.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b73118-a325-4dc1-a537-d7986dd2f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and saving metrics\n",
    "(predictions_alexnet, labels_alexnet, probs_alexnet, fpr_alexnet, tpr_alexnet, roc_auc_alexnet,\n",
    "misclassified_test_paths_alexnet) = calculate_roc_latef([net0, net1, net2], testloader, pred_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "285a340b-315c-4bd8-a649-6324ac8f1352",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_test_df = misclassified_paths_df(misclassified_test_paths_alexnet, 'alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33fe1fbb-5392-49d7-8630-9ef4e9239e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results using pickle\n",
    "with open('roc_results_alexnet_late_fusion.pkl', 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'predictions': predictions_alexnet,\n",
    "        'labels': labels_alexnet,\n",
    "        'probs': probs_alexnet,\n",
    "        'fpr': fpr_alexnet,\n",
    "        'tpr': tpr_alexnet,\n",
    "        'roc_auc': roc_auc_alexnet,\n",
    "        'misclassified_test_paths': misclassified_test_paths_alexnet\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2c71b-5c9a-4803-946e-23af696fa8a1",
   "metadata": {},
   "source": [
    "## vgg11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc43b5-fe2e-42ba-80e9-090baf450228",
   "metadata": {},
   "source": [
    "## vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e6c79-306a-4bd9-94c6-34e43ba37401",
   "metadata": {},
   "source": [
    "## Misclassified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195261f5-e257-448e-9a39-067632f6424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_images_late_fusion_df = pd.concat([alex_test_df, vgg11_test_df, vgg19_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfedebd-4ace-41e2-9a14-5084e21a61d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the paths in csv format\n",
    "wrong_images_late_fusion_df.to_csv('wrong_images_late_fusion_from_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd1562a-f4cd-43ea-8ee0-068f7ea97bb8",
   "metadata": {},
   "source": [
    "# Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86174219-04f1-448b-b44c-952cae2d997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(outputs, METHOD = 'mean_probability', pred_threshold = 0.5):\n",
    "\n",
    "    if METHOD == \"voting\":\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted\n",
    "\n",
    "    elif METHOD == \"mean_probability\":\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        predicted = probabilities[:, 1] >= pred_threshold\n",
    "        return predicted, probabilities[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d559a34-edc0-40a8-8348-07725c869838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_earlyf(net, testloader, pred_threshold):\n",
    "    \n",
    "    correct = 0\n",
    "    misclassified_test_paths = []\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, true_labels, img_paths in tqdm.tqdm(testloader, desc=f'Testing {NETWORK} - Early Fusion'):\n",
    "            imgs, true_labels = imgs.cuda().float(), true_labels.cuda()\n",
    "            outputs = net(imgs)\n",
    "            \n",
    "            method = 'mean_probability' # or 'voting'\n",
    "            predicted, prob = prediction(outputs, method, pred_threshold)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            labels.extend(true_labels.cpu().numpy())\n",
    "            probs.extend(prob.cpu().numpy())\n",
    "            \n",
    "            indices_wrong = torch.nonzero(predicted != true_labels).squeeze().tolist()\n",
    "            if type(indices_wrong) is int:\n",
    "                indices_wrong = [indices_wrong]\n",
    "            for idx in indices_wrong:\n",
    "                for img_path in img_paths:\n",
    "                    misclassified_test_paths.append(img_path[idx])\n",
    " \n",
    "            correct += (predicted == true_labels).sum()\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    print(f\"{NETWORK.capitalize()} - Early fusion - Test accuracy: {100*correct/len(labels):.2f}\\n\")\n",
    "    print(f\"{NETWORK.capitalize()} evaluation completed\\n\")\n",
    "\n",
    "\n",
    "    return predictions, labels, probs, fpr, tpr, roc_auc, misclassified_test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44ddc8-24df-4f7c-97b0-4e9ee0a0586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_ef = {\n",
    "    'alexnet' : \"alexnet_epoch.pth\",\n",
    "    'vgg11' : \"vgg11_epoch.pth\",\n",
    "    'vgg19' : \"vgg19_epoch.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f402e5-f57c-44d8-be3a-4844aefa2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PhysicsImageDataset(subset='test')\n",
    "print(\"Test dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63606abb-c93a-4c8d-800a-8f610a10c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset.files[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418608d-f640-44b1-b754-8f03674c1f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346d75e-1146-40fa-bb15-f12170a81f49",
   "metadata": {},
   "source": [
    "## alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3375bfd-91cc-46d0-aace-903634cfa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK = 'alexnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2428b864-2830-4378-9e7d-9c7ab3c2ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_network(model_path=paths_ef)\n",
    "net.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e590c-4a32-4244-b4ac-ab4155de3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions_alexnet, labels_alexnet, probs_alexnet, fpr_alexnet, tpr_alexnet, roc_auc_alexnet,\n",
    "misclassified_test_paths_alexnet) = calculate_roc_earlyf(net, testloader, pred_threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac992b-0b0d-40cb-be85-c7ba7774e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_test_df = misclassified_paths_df(misclassified_test_paths_alexnet, 'alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399616da-8670-4d6f-a796-d256e162ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('roc_results_alexnet_early_fusion.pkl', 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'predictions': predictions_alexnet,\n",
    "        'labels': labels_alexnet,\n",
    "        'probs': probs_alexnet,\n",
    "        'fpr': fpr_alexnet,\n",
    "        'tpr': tpr_alexnet,\n",
    "        'roc_auc': roc_auc_alexnet,\n",
    "        'misclassified_test_paths': misclassified_test_paths_alexnet\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485c713-aec8-4775-b705-6010c44ebc21",
   "metadata": {},
   "source": [
    "## vgg11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73cc94e-a8b0-4273-b0e8-b6236f2f128f",
   "metadata": {},
   "source": [
    "## vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a2676a-8947-4e6b-a64f-18b76d336efb",
   "metadata": {},
   "source": [
    "## Misclassified Images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
